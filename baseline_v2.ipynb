{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96960674-de45-472b-b5f7-75de77d274a6",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3d45d4-620f-4a3b-a03d-654375a3eb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "import cv2\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(42)\n",
    "\n",
    "print(os.listdir('../data'))\n",
    "print(os.listdir('../data/train_images'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac30282a-db47-41ac-8237-f2441f6a2fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../data/train.csv')\n",
    "df_train['filepath'] = df_train['label'] + '/' + df_train['image_id']\n",
    "print(df_train.shape)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2c79fe-4c4e-4589-a6dd-0265a03cca1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "df_train['label'] = le.fit_transform(df_train['label'])\n",
    "df_train['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7640ee6b-4ce0-4a52-a784-13cc55e45e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a82b289-40d7-4251-b37d-4f775c832655",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PaddyDataset(Dataset):\n",
    "    def __init__(self, df, labels, transforms=None):\n",
    "        self.df = df\n",
    "        self.labels = labels\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_id = self.df['filepath'].values[index]\n",
    "        fpath = f'../data/train_images/{image_id}'\n",
    "        \n",
    "        image = cv2.imread(fpath, cv2.IMREAD_COLOR)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        if self.transforms:\n",
    "            image = self.transforms(image=image)\n",
    "            image = image['image']\n",
    "\n",
    "        label = self.labels[index]\n",
    "\n",
    "        return torch.tensor(image), torch.tensor(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bcb8e97-7f3d-40f1-8fd2-09c04786e829",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms_train = A.Compose([\n",
    "    A.Resize(224, 224, p=1.0),\n",
    "    A.Flip(),\n",
    "    A.RandomBrightnessContrast(p=0.5),\n",
    "    A.ShiftScaleRotate(p=0.5), \n",
    "    A.Normalize(p=1.0),\n",
    "    ToTensorV2(),                               \n",
    "])\n",
    "\n",
    "transforms_valid = A.Compose([   \n",
    "    A.Resize(224, 224, p=1.0),                   \n",
    "    A.Normalize(p=1.0),\n",
    "    ToTensorV2(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f75a549-ec53-45e5-aa3b-e06c7b48651f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image = PaddyDataset(df_train[:1000].reset_index(drop=True), df_train[:1000].reset_index(drop=True)['label'], transforms=transforms_train)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 20, 10\n",
    "for i in range(2):\n",
    "    f, axarr = plt.subplots(1, 5)\n",
    "    for p in range(5):\n",
    "        idx = np.random.randint(0, len(train_image))\n",
    "        img, label = train_image[idx]\n",
    "        axarr[p].imshow(img.transpose(0, 1).transpose(1, 2))\n",
    "        axarr[p].set_title(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d9bd45-0951-4c3b-bc8c-6c566b1b77c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "    \n",
    "class resnet34(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(resnet34, self).__init__()\n",
    "        \n",
    "        self.base_model = timm.create_model('resnet34', pretrained=True)\n",
    "        self.base_model.fc = nn.Linear(in_features=512, out_features=10, bias=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.base_model(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c7f9a6-1703-40f9-808d-6664f617c624",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop_fn(model, loader, optimizer, loss_func, scheduler, device, epoch, scaler):\n",
    "    model.train()\n",
    "\n",
    "    TRAIN_LOSS = []\n",
    "\n",
    "    bar = tqdm(enumerate(loader), total=len(loader))\n",
    "\n",
    "    for step, (data, target) in bar:\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        with autocast():\n",
    "            outputs = model(data)\n",
    "            loss = loss_func(outputs, target)\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "\n",
    "            TRAIN_LOSS.append(loss.item())\n",
    "            smooth_loss = np.mean(TRAIN_LOSS[-30:])\n",
    "            bar.set_description(f'loss: {loss.item():.5f}, smth: {smooth_loss:.5f}')\n",
    "\n",
    "            if ((step + 1) % 2 == 0) or ((step + 1) == len(loader)):\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "     \n",
    "        scheduler.step(epoch)\n",
    "\n",
    "        avg_train_loss = np.mean(TRAIN_LOSS)\n",
    "    \n",
    "    return avg_train_loss\n",
    "\n",
    "\n",
    "def valid_loop_fn(model, loader, loss_func, device):\n",
    "    model.eval()\n",
    "\n",
    "    correct = 0.0\n",
    "    total_samples = 0.0\n",
    "\n",
    "    VAL_LOSS = []\n",
    "\n",
    "    bar = tqdm(enumerate(loader), total=len(loader))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for step, (data, target) in bar:\n",
    "\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "            \n",
    "            outputs = model(data)\n",
    "\n",
    "            pred = outputs.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            total_samples += data.size()[0]\n",
    "            loss = loss_func(outputs, target)\n",
    "\n",
    "            VAL_LOSS.append(loss.item())\n",
    "\n",
    "            smooth_loss = np.mean(VAL_LOSS[-30:])\n",
    "            bar.set_description(f'loss: {loss.item():.5f}, smth: {smooth_loss:.5f}')\n",
    "\n",
    "    avg_valid_loss = np.mean(VAL_LOSS)\n",
    "    accuracy = 100.0 * correct / total_samples\n",
    "\n",
    "    return avg_valid_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c301b336-4365-44c3-ab18-fde4de7f1a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skf = StratifiedKFold(5, shuffle=True, random_state=42)\n",
    "df_train['fold'] = -1\n",
    "for i, (train_idx, valid_idx) in enumerate(skf.split(df_train, df_train['label'])):\n",
    "    df_train.loc[valid_idx, 'fold'] = i\n",
    "df_train.to_csv('folds.csv', index=False)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa96e68-7ad7-487f-acd9-a4df2f0d32ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_gpu = torch.cuda.device_count()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = resnet34().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-6)\n",
    "\n",
    "scheduler = lr_scheduler.CosineAnnealingLR(optimizer, 5)\n",
    "loss_func = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5478a717-4b0c-45fe-b518-123cdce806e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = df_train.copy()\n",
    "N_FOLDS = 5\n",
    "\n",
    "def run(fold):\n",
    "    \n",
    "    print(f\"Fold: {fold+1} / {N_FOLDS}\")\n",
    "\n",
    "    train_idx = np.where((folds['fold'] != fold))[0]\n",
    "    valid_idx = np.where((folds['fold'] == fold))[0]\n",
    "\n",
    "    df_this  = folds.loc[train_idx].reset_index(drop=True)\n",
    "    df_valid = folds.loc[valid_idx].reset_index(drop=True)\n",
    "\n",
    "    dataset_train = PaddyDataset(df_this, df_this['label'], transforms=transforms_train)\n",
    "    dataset_valid = PaddyDataset(df_valid, df_valid['label'], transforms=transforms_valid)\n",
    "\n",
    "    train_loader = DataLoader(dataset_train, batch_size=16, num_workers=4, shuffle=True)\n",
    "    valid_loader = DataLoader(dataset_valid, batch_size=32, num_workers=4, shuffle=False)\n",
    "\n",
    "    kernel_type = 'resnet34'\n",
    "    best_file = f'./models/{kernel_type}_best_fold{fold}.bin'\n",
    "    acc_max = float('-inf')\n",
    "\n",
    "    for epoch in range(5):\n",
    "        \n",
    "        scaler = GradScaler()\n",
    "        avg_train_loss = train_loop_fn(model, train_loader, optimizer, loss_func, scheduler, device, epoch, scaler)     \n",
    "        avg_valid_loss, accuracy = valid_loop_fn(model, valid_loader, loss_func, device)\n",
    "      \n",
    "        content = f\"Epoch: {epoch+1} | lr: {optimizer.param_groups[0]['lr']:.7f} | train loss: {avg_train_loss:.4f} | val loss: {avg_valid_loss:.4f} | accuracy: {accuracy:.4f}\"\n",
    "        print(content)\n",
    "\n",
    "        with open(f'log_{kernel_type}.txt', 'a') as appender:\n",
    "            appender.write(content + '\\n')\n",
    "\n",
    "        if accuracy > acc_max:\n",
    "            print('score2 ({:.6f} --> {:.6f}).  Saving model ...'.format(acc_max, accuracy))\n",
    "            torch.save(model.state_dict(), best_file)\n",
    "            acc_max = accuracy\n",
    "\n",
    "        torch.save(model.state_dict(), f'./models/{kernel_type}_final_fold.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e694749-8cdd-43f2-9cc9-0cd08e2e756b",
   "metadata": {},
   "outputs": [],
   "source": [
    "run(0)\n",
    "run(1)\n",
    "run(2)\n",
    "run(3)\n",
    "run(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b4aa04-771e-45de-ac13-66913f387d50",
   "metadata": {},
   "source": [
    "### Grab OOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114df78c-224b-4be7-9910-6b0ead1ff02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Grab OOF\n",
    "\n",
    "oof = np.zeros((len(df_train), 1)) \n",
    "\n",
    "for fold in range(5):\n",
    "    valid_idx = np.where((folds['fold'] == fold))[0]\n",
    "    df_valid = folds.loc[valid_idx].reset_index(drop=True)\n",
    "    dataset_valid = PaddyDataset(df_valid, df_valid['label'], transforms=transforms_valid)\n",
    "    valid_loader = DataLoader(dataset_valid, batch_size=32, num_workers=4, shuffle=False)\n",
    "    \n",
    "    model = resnet34()\n",
    "    model.load_state_dict(torch.load(f'./models/resnet34_best_fold{fold}.bin'))\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    bar = tqdm(enumerate(valid_loader), total=len(valid_loader))\n",
    "    val_preds = torch.zeros((len(valid_idx), 1), dtype=torch.float32, device=device) \n",
    "\n",
    "    with torch.no_grad():\n",
    "        for step, (data, target) in bar:\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "            logit = model(data)\n",
    "            pred = torch.argmax(logit, dim=1).unsqueeze(1)\n",
    "            val_preds[step*32:step*32+32] = pred\n",
    "        oof[valid_idx] = val_preds.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25579809-8912-4c56-8f1b-47619287131b",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'oof': np.squeeze(oof)}\n",
    "oof_df = pd.DataFrame(data=d)\n",
    "oof_df['oof'] = oof_df['oof'].astype(int)\n",
    "oof_df.to_csv('oof_df_resnet34.csv')\n",
    "oof_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cf88b7-3f3b-47b9-a8bf-588959a46366",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../data/train.csv')\n",
    "mapping = dict(enumerate(df_train['label'].unique()))\n",
    "oof_df['oof'] = oof_df['oof'].map(mapping)\n",
    "oof_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e27954-1814-4722-80c3-945483a9729b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['filepath'] = df_train['label'] + '/' + df_train['image_id']\n",
    "result = pd.concat([oof_df['oof'], df_train[['label', 'image_id', 'filepath']]], axis=1)\n",
    "result['incorrect_preds'] = result['oof'] != result['label']\n",
    "wrong_preds_df = result[result['incorrect_preds'] == True]\n",
    "wrong_preds_df.to_csv('wrong_preds_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d0574f-ac79-4f83-89ec-68fed7dff9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_preds_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2e27fc-e5da-42c4-bee2-d2f5953b5597",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_preds_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1e08a4-927e-4ef8-b4e1-f7aa7e82091e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(df_train['label'], oof_df['oof'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa72e05-03e4-4eff-acc0-d6914e12f53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrong_preds_df['oof'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2294d1a-1632-40e2-a4e3-fda36ab55491",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PaddyDataset(Dataset):\n",
    "    def __init__(self, df, labels, oof_pred, transforms=None):\n",
    "        self.df = df\n",
    "        self.labels = labels\n",
    "        self.oof_pred = oof_pred\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_id = self.df['filepath'].values[index]\n",
    "        fpath = f'../data/train_images/{image_id}'\n",
    "        \n",
    "        image = cv2.imread(fpath, cv2.IMREAD_COLOR)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        if self.transforms:\n",
    "            image = self.transforms(image=image)\n",
    "            image = image['image']\n",
    "\n",
    "        label = self.labels[index]\n",
    "        oof_pred = self.oof_pred[index]\n",
    "\n",
    "        return torch.tensor(image), label, oof_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73991f15-657e-4017-8d01-58e63652c722",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image = PaddyDataset(wrong_preds_df.reset_index(drop=True), \n",
    "                           wrong_preds_df.reset_index(drop=True)['label'], \n",
    "                           wrong_preds_df.reset_index(drop=True)['oof'], \n",
    "                           transforms=transforms_valid)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 20, 10\n",
    "for i in range(2):\n",
    "    f, axarr = plt.subplots(1, 5)\n",
    "    for p in range(5):\n",
    "        idx = np.random.randint(0, len(train_image))\n",
    "        img, label, oof_pred = train_image[idx]\n",
    "        axarr[p].imshow(img.transpose(0, 1).transpose(1, 2))\n",
    "        axarr[p].set_title(f\"Label: {label},\\nIncorrect Pred: {oof_pred}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f90efb-4777-4f82-b249-97ed1c1150e9",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8885849-e92a-48a5-a812-ccd82d6de3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PaddyTestDataset(Dataset):\n",
    "    def __init__(self, df, transforms=None):\n",
    "        self.df = df\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_id = self.df['image_id'].values[index]\n",
    "        fpath = f'../data/test_images/{image_id}'\n",
    "        \n",
    "        image = cv2.imread(fpath, cv2.IMREAD_COLOR)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        if self.transforms:\n",
    "            image = self.transforms(image=image)\n",
    "            image = image['image']\n",
    "\n",
    "        return torch.tensor(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205a633d-06be-4478-b496-4d657cfa4373",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'image_id': sorted(os.listdir('../data/test_images/'))}\n",
    "df_test = pd.DataFrame(data=data)\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e8989e-254b-47fc-a139-aee71685d105",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.read_csv('../data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5badbd30-9694-466c-b11b-657357d8f660",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms_test = A.Compose([   \n",
    "    A.Resize(224, 224, p=1.0),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.Normalize(p=1.0),\n",
    "    ToTensorV2(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165f014b-5dd0-45e0-ab6e-665706325619",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = PaddyTestDataset(df_test[:1000].reset_index(drop=True), transforms=transforms_test)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 20, 10\n",
    "for i in range(2):\n",
    "    f, axarr = plt.subplots(1, 5)\n",
    "    for p in range(5):\n",
    "        idx = np.random.randint(0, len(test_image))\n",
    "        img = test_image[idx]\n",
    "        axarr[p].imshow(img.transpose(0, 1).transpose(1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fa34b5-62bc-4e8d-9cf2-e231734490e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = PaddyTestDataset(df_test, transforms=transforms_test)\n",
    "test_loader = DataLoader(dataset_test, batch_size=32, num_workers=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e180d0b2-4a40-400b-9c6e-e4c64825b366",
   "metadata": {},
   "outputs": [],
   "source": [
    "TTA = 3\n",
    "N_FOLDS = 5\n",
    "\n",
    "def run_tta(fold):\n",
    "    \n",
    "    preds = torch.zeros((len(dataset_test), 1), dtype=torch.float32, device=device) \n",
    "    \n",
    "    model = resnet34()\n",
    "    model.load_state_dict(torch.load(f'./models/resnet34_best_fold{fold}.bin'))\n",
    "    model = model.to(device)\n",
    "\n",
    "    tta_preds = torch.zeros((len(dataset_test), 1), dtype=torch.float32, device=device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for tta_fold in range(TTA):\n",
    "            print(f'TTA: {tta_fold}')\n",
    "            for i, batch in tqdm(enumerate(test_loader), total=len(test_loader)):\n",
    "                image = batch.to(device, dtype=torch.float32)\n",
    "                logit = model(image)\n",
    "                pred = torch.argmax(logit, dim=1).unsqueeze(1)\n",
    "                tta_preds[i*32:i*32+32] += pred\n",
    "        preds += tta_preds // TTA\n",
    "    \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5532ea-04e0-49b2-9718-69f97ffe3850",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold0_tta = run_tta(0)\n",
    "fold1_tta = run_tta(1)\n",
    "fold2_tta = run_tta(2)\n",
    "fold3_tta = run_tta(3)\n",
    "fold4_tta = run_tta(4)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3a5f50-768d-4664-98e3-ac8167cd7e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 - vertical, 1 - horizontal\n",
    "# horizontally concat. preds per fold \n",
    "horizontal_stack = torch.cat((fold0_tta, fold1_tta, fold2_tta, fold3_tta, fold4_tta), 1)\n",
    "print(horizontal_stack.shape)\n",
    "print(horizontal_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115e646f-96d2-4898-af88-b981de9eff94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the most frequently occurring (mode) pred and use that\n",
    "values, indices = torch.mode(horizontal_stack, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5514f62d-7e19-45f8-aea4-2d0071f9ab17",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample['label'] = values.cpu().detach().numpy().astype(int)\n",
    "sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9511f46e-006f-46ef-8125-80eb84b88c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb61304-5cb1-4c0e-a47c-0ddaa533f761",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744d192c-6c43-4ec7-9b64-fbaccd7880c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = dict(enumerate(df_train['label'].unique()))\n",
    "mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb47d7e-05ad-4551-8e6a-6c03398638e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample['label'] = sample['label'].map(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee38e355-7cfb-484e-ae36-0ed6388a77bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c330f67-2729-497a-92c2-8c201a667572",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2324989-232f-4faf-a13d-33b1805a1b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "! kaggle competitions submit -f submission.csv -m 'resnet34 baseline 5fold 3tta' paddy-disease-classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5876a3e4-9e71-488f-a764-bc19e4d3a71a",
   "metadata": {},
   "source": [
    "### Pseudo-Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d7d795-9e55-4239-9031-e9621b3996aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../data/train.csv')\n",
    "df_train[\"pl\"] = np.zeros_like(df_train[\"image_id\"])\n",
    "# df_train['filepath'] = df_train['label'] + '/' + df_train['image_id']\n",
    "print(df_train.shape)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5691920c-9603-4e3c-bf9e-5e473c8aa4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.concat([df_train, sample]).reset_index()\n",
    "print(df_train.shape)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfeee4a-5a0d-4225-9bf7-012c037a1a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8706ee1-ad85-4be1-9f7e-b68acc0c288f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['filepath'] = df_train['label'] + '/' + df_train['image_id']\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec40e568-d947-4bc1-90bb-c963e41758bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ed8930-5ebe-4503-9cb9-b419b8809b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "df_train['label'] = le.fit_transform(df_train['label'])\n",
    "df_train['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d39785-695d-420d-8ff5-439f36932b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd85140-36e0-409b-ac59-294cf7ad90a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PaddyDataset2(Dataset):\n",
    "    def __init__(self, df, labels, transforms=None):\n",
    "        self.df = df\n",
    "        self.labels = labels\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_id = self.df['filepath'].values[index]\n",
    "        test_image_id = self.df['image_id'].values[index]\n",
    "        # fpath = f'../data/train_images/{image_id}'\n",
    "        dir = self.df['pl'].values[index]\n",
    "        \n",
    "        if dir:\n",
    "            fpath = f'../data/test_images/{test_image_id}'\n",
    "        else:\n",
    "            fpath = f'../data/train_images/{image_id}'\n",
    "        \n",
    "        image = cv2.imread(fpath, cv2.IMREAD_COLOR)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        if self.transforms:\n",
    "            image = self.transforms(image=image)\n",
    "            image = image['image']\n",
    "\n",
    "        label = self.labels[index]\n",
    "\n",
    "        return torch.tensor(image), torch.tensor(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f33ae0-7a0f-469a-8543-3aabaf7d4bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image = PaddyDataset2(df_train[:1000].reset_index(drop=True), df_train[:1000].reset_index(drop=True)['label'], transforms=transforms_train)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 20, 10\n",
    "for i in range(2):\n",
    "    f, axarr = plt.subplots(1, 5)\n",
    "    for p in range(5):\n",
    "        idx = np.random.randint(0, len(train_image))\n",
    "        img, label = train_image[idx]\n",
    "        axarr[p].imshow(img.transpose(0, 1).transpose(1, 2))\n",
    "        axarr[p].set_title(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58e1e08-3153-4b50-aa28-f5964080ce92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't re-reun this cell use the already existing folds.csv file\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skf = StratifiedKFold(5, shuffle=True, random_state=42)\n",
    "df_train['fold'] = -1\n",
    "for i, (train_idx, valid_idx) in enumerate(skf.split(df_train, df_train['label'])):\n",
    "    df_train.loc[valid_idx, 'fold'] = i\n",
    "df_train.to_csv('folds.csv', index=False)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f809bb-1519-4750-b90e-7c978fa848df",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_gpu = torch.cuda.device_count()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = resnet34().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-6)\n",
    "\n",
    "scheduler = lr_scheduler.CosineAnnealingLR(optimizer, 5)\n",
    "loss_func = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1cec8c-92c5-4c85-9364-4da5db257e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = df_train.copy()\n",
    "N_FOLDS = 5\n",
    "\n",
    "def run(fold):\n",
    "    \n",
    "    print(f\"Fold: {fold+1} / {N_FOLDS}\")\n",
    "\n",
    "    train_idx = np.where((folds['fold'] != fold))[0]\n",
    "    valid_idx = np.where((folds['fold'] == fold))[0]\n",
    "\n",
    "    df_this  = folds.loc[train_idx].reset_index(drop=True)\n",
    "    df_valid = folds.loc[valid_idx].reset_index(drop=True)\n",
    "\n",
    "    dataset_train = PaddyDataset2(df_this, df_this['label'], transforms=transforms_train)\n",
    "    dataset_valid = PaddyDataset2(df_valid, df_valid['label'], transforms=transforms_valid)\n",
    "\n",
    "    train_loader = DataLoader(dataset_train, batch_size=16, num_workers=4, shuffle=True)\n",
    "    valid_loader = DataLoader(dataset_valid, batch_size=32, num_workers=4, shuffle=False)\n",
    "\n",
    "    kernel_type = 'resnet34_pl'\n",
    "    best_file = f'./models/{kernel_type}_best_fold{fold}.bin'\n",
    "    acc_max = float('-inf')\n",
    "\n",
    "    for epoch in range(5):\n",
    "        \n",
    "        scaler = GradScaler()\n",
    "        avg_train_loss = train_loop_fn(model, train_loader, optimizer, loss_func, scheduler, device, epoch, scaler)     \n",
    "        avg_valid_loss, accuracy = valid_loop_fn(model, valid_loader, loss_func, device)\n",
    "      \n",
    "        content = f\"Epoch: {epoch+1} | lr: {optimizer.param_groups[0]['lr']:.7f} | train loss: {avg_train_loss:.4f} | val loss: {avg_valid_loss:.4f} | accuracy: {accuracy:.4f}\"\n",
    "        print(content)\n",
    "\n",
    "        with open(f'log_{kernel_type}.txt', 'a') as appender:\n",
    "            appender.write(content + '\\n')\n",
    "\n",
    "        if accuracy > acc_max:\n",
    "            print('score2 ({:.6f} --> {:.6f}).  Saving model ...'.format(acc_max, accuracy))\n",
    "            torch.save(model.state_dict(), best_file)\n",
    "            acc_max = accuracy\n",
    "\n",
    "        torch.save(model.state_dict(), f'{kernel_type}_final_fold.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a468cd15-b49d-430a-9191-b75b3868e46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "run(0)\n",
    "run(1)\n",
    "run(2)\n",
    "run(3)\n",
    "run(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e85753-d9ab-45d1-8cfc-667f26a01f42",
   "metadata": {},
   "source": [
    "### Testing Pseudo-Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb3fd7f-4e31-45b4-9eea-ab7372b649f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PaddyTestDataset(Dataset):\n",
    "    def __init__(self, df, transforms=None):\n",
    "        self.df = df\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_id = self.df['image_id'].values[index]\n",
    "        fpath = f'../data/test_images/{image_id}'\n",
    "        \n",
    "        image = cv2.imread(fpath, cv2.IMREAD_COLOR)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        if self.transforms:\n",
    "            image = self.transforms(image=image)\n",
    "            image = image['image']\n",
    "\n",
    "        return torch.tensor(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2943feb3-e992-4d14-af73-e1730dd1ae2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'image_id': sorted(os.listdir('../data/test_images/'))}\n",
    "df_test = pd.DataFrame(data=data)\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a088373b-8b42-4dbf-8198-dacba37aa228",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.read_csv('../data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d68c797-ee71-477f-9880-a5f3d52e848d",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms_test = A.Compose([   \n",
    "    A.Resize(224, 224, p=1.0),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.Normalize(p=1.0),\n",
    "    ToTensorV2(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b24eb59-49a0-4025-8d47-52e4fbf0e951",
   "metadata": {},
   "outputs": [],
   "source": [
    "TTA = 3\n",
    "N_FOLDS = 5\n",
    "\n",
    "def run_tta(fold):\n",
    "    \n",
    "    preds = torch.zeros((len(dataset_test), 1), dtype=torch.float32, device=device) \n",
    "    \n",
    "    model = resnet34()\n",
    "    model.load_state_dict(torch.load(f'./models/resnet34_pl_best_fold{fold}.bin'))\n",
    "    model = model.to(device)\n",
    "\n",
    "    tta_preds = torch.zeros((len(dataset_test), 1), dtype=torch.float32, device=device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for tta_fold in range(TTA):\n",
    "            print(f'TTA: {tta_fold}')\n",
    "            for i, batch in tqdm(enumerate(test_loader), total=len(test_loader)):\n",
    "                image = batch.to(device, dtype=torch.float32)\n",
    "                logit = model(image)\n",
    "                pred = torch.argmax(logit, dim=1).unsqueeze(1)\n",
    "                tta_preds[i*32:i*32+32] += pred\n",
    "        preds += tta_preds // TTA\n",
    "    \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e160f35-e35b-4b3f-8cb0-0170f119ce2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold0_tta = run_tta(0)\n",
    "fold1_tta = run_tta(1)\n",
    "fold2_tta = run_tta(2)\n",
    "fold3_tta = run_tta(3)\n",
    "fold4_tta = run_tta(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed79266-6c5c-430b-a7d6-c0a9a2b465ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 - vertical, 1 - horizontal\n",
    "# horizontally concat. preds per fold \n",
    "horizontal_stack = torch.cat((fold0_tta, fold1_tta, fold2_tta, fold3_tta, fold4_tta), 1)\n",
    "print(horizontal_stack.shape)\n",
    "print(horizontal_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75020874-d14c-44ab-b6b0-9d698b448fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "horizontal_stack[-3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3daf1429-122b-48f6-b571-4ad36f6c5bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "values[-3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e3948c-afe4-4b72-a035-e285b09ff5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the most frequently occurring (mode) pred and use that\n",
    "values, indices = torch.mode(horizontal_stack, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d13dfb7-f7e2-46e2-a078-b270a06ba4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample['label'] = values.cpu().detach().numpy().astype(int)\n",
    "sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a238f7bf-4c14-4164-bf29-b5db18414a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07883667-77c1-43f4-adf3-5b533c78111e",
   "metadata": {},
   "outputs": [],
   "source": [
    "_df_train = pd.read_csv('../data/train.csv')\n",
    "_df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cce57fd-24f0-4a2e-92f2-6c8d60250776",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = dict(enumerate(_df_train['label'].unique()))\n",
    "mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0b92b3-0e4f-4c84-806b-c3d08327cd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample['label'] = sample['label'].map(mapping)\n",
    "\n",
    "sample.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a92f024-9bda-4570-851f-129ec61aa828",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063ba86f-704b-4129-a464-50fd780fcf06",
   "metadata": {},
   "outputs": [],
   "source": [
    "! kaggle competitions submit -f submission.csv -m 'resnet34 pseudo label baseline 5fold 3tta' paddy-disease-classification"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
